# describes the mcp servers to use
mcpServers:
  filesystem:
    type: stdio
    command: npx
    args:
      - -y
      - "@modelcontextprotocol/server-filesystem"
      - .

# describes the llm configuration
# llm:
#   # OpenRouter configuration - Updated to use model that supports tool calling
#   provider: openrouter
#   model: o4-mini  
#   apiKey: $OPENROUTER_API_KEY
#   maxIterations: 50

# # System prompt
# systemPrompt: "You are a helpful AI assistant with memory capabilities. Please confirm you're working with OpenRouter API."






#Ollama configuration
llm:
  provider: ollama
  model: qwen3:32b      # Use the model you downloaded
  maxIterations: 50
  baseURL: $OLLAMA_BASE_URL 

#System Prompt
systemPrompt: "You are a helpful AI assistant with memory capabilities running on Ollama. You have access to local files and can perform various tasks using the available tools."
