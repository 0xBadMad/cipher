# describes the mcp servers to use
mcpServers:
  filesystem:
    type: stdio
    command: npx
    args:
      - -y
      - "@modelcontextprotocol/server-filesystem"
      - .

# describes the llm configuration
llm:
  # OpenRouter configuration - Updated to use model that supports tool calling
  provider: openrouter
  model: openai/gpt-4o-mini    # Free model with tool calling support
  apiKey: $OPENROUTER_API_KEY
  maxIterations: 50

# System prompt
systemPrompt: "You are a helpful AI assistant with memory capabilities. Please confirm you're working with OpenRouter API."