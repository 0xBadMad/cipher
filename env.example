# =============================================================================
# CIPHER PROJECT ENVIRONMENT CONFIGURATION
# =============================================================================
# This file contains all available environment variables for the Cipher project.
# Copy this file to .env and configure the values according to your setup.

# =============================================================================
# GENERAL CONFIGURATION
# =============================================================================

# Environment mode: development, production, or test
NODE_ENV=development

# Logging level: debug, info, warn, error
CIPHER_LOG_LEVEL=info

# Whether to redact secrets in logs (true/false)
REDACT_SECRETS=true

# =============================================================================
# LLM PROVIDER CONFIGURATION
# =============================================================================

# OpenAI Configuration
# Your OpenAI API key (REQUIRED for embedding functionality, even when using other LLM providers)
# This is needed because embeddings currently only support OpenAI
OPENAI_API_KEY=sk-your-openai-api-key

# OpenAI Organization ID (optional)
OPENAI_ORG_ID=org-your-organization-id

# OpenAI API Base URL (optional, defaults to https://api.openai.com/v1)
OPENAI_BASE_URL=https://api.openai.com/v1

# Anthropic Configuration
# Your Anthropic API key (required for Anthropic/Claude services)
# Note: You still need OPENAI_API_KEY above for embedding functionality
ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here

# OpenRouter Configuration  
# Your OpenRouter API key (required for OpenRouter services)
# Note: You still need OPENAI_API_KEY above for embedding functionality
OPENROUTER_API_KEY=sk-or-your-openrouter-api-key-here

# =============================================================================
# EMBEDDING CONFIGURATION
# =============================================================================
# IMPORTANT: Embeddings currently only support OpenAI.
# OPENAI_API_KEY is REQUIRED above, regardless of which LLM provider you use.

# Embedding model to use (optional)
# Supported OpenAI models: text-embedding-3-small, text-embedding-3-large, text-embedding-ada-002
# Default: text-embedding-3-small
EMBEDDING_MODEL=text-embedding-3-small

# Request timeout for embedding operations in milliseconds (optional)
# Default: 30000 (30 seconds)
EMBEDDING_TIMEOUT=30000

# Maximum number of retry attempts for failed embedding requests (optional)
# Default: 3
EMBEDDING_MAX_RETRIES=3

# =============================================================================
# STORAGE CONFIGURATION
# =============================================================================

# Cache Storage Configuration
# Storage type for caching: redis, in-memory
STORAGE_CACHE_TYPE=in-memory

# Redis configuration (only used if STORAGE_CACHE_TYPE=redis)
STORAGE_CACHE_HOST=localhost
STORAGE_CACHE_PORT=6379
STORAGE_CACHE_PASSWORD=your-redis-password
STORAGE_CACHE_DATABASE=0

# Database Storage Configuration
# Database type: sqlite, in-memory
STORAGE_DATABASE_TYPE=in-memory

# SQLite configuration (only used if STORAGE_DATABASE_TYPE=sqlite)
STORAGE_DATABASE_PATH=./data/cipher.db
STORAGE_DATABASE_NAME=cipher

# =============================================================================
# VECTOR STORAGE CONFIGURATION
# =============================================================================

# Vector store type: qdrant, in-memory
VECTOR_STORE_TYPE=in-memory

# Qdrant configuration (only used if VECTOR_STORE_TYPE=qdrant)
VECTOR_STORE_HOST=localhost
VECTOR_STORE_PORT=6333
VECTOR_STORE_URL=http://localhost:6333
VECTOR_STORE_API_KEY=your-qdrant-api-key

# Vector collection settings
VECTOR_STORE_COLLECTION=default
VECTOR_STORE_DIMENSION=1536

# Distance metric: Cosine, Euclidean, Dot, Manhattan
VECTOR_STORE_DISTANCE=Cosine

# Whether to store vectors on disk (true/false)
VECTOR_STORE_ON_DISK=false

# Maximum number of vectors for in-memory storage
VECTOR_STORE_MAX_VECTORS=10000

# =============================================================================
# DEVELOPMENT NOTES
# =============================================================================
#
# Required Variables:
# - OPENAI_API_KEY (ALWAYS required for embedding functionality)
# - At least one LLM provider API key for chat/completion services:
#   * OPENAI_API_KEY (can serve both LLM and embedding needs)
#   * ANTHROPIC_API_KEY (for Claude, but still need OPENAI_API_KEY for embeddings)
#   * OPENROUTER_API_KEY (for OpenRouter, but still need OPENAI_API_KEY for embeddings)
#
# Optional Variables:
# - All other variables have sensible defaults and can be omitted
#
# Common Configurations:
#
# 1. OpenAI for both LLM and embeddings (minimal setup):
#    NODE_ENV=development
#    CIPHER_LOG_LEVEL=debug
#    OPENAI_API_KEY=sk-your-openai-key-here
#
# 2. Anthropic for LLM + OpenAI for embeddings:
#    NODE_ENV=development
#    OPENAI_API_KEY=sk-your-openai-key-here
#    ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here
#
# 3. Production with Qdrant and Anthropic:
#    NODE_ENV=production
#    CIPHER_LOG_LEVEL=info
#    OPENAI_API_KEY=sk-your-openai-key-here
#    ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here
#    VECTOR_STORE_TYPE=qdrant
#    VECTOR_STORE_URL=https://your-qdrant-instance.com
#    VECTOR_STORE_API_KEY=your-qdrant-key
#
# 4. Development with Redis cache and mixed providers:
#    NODE_ENV=development
#    OPENAI_API_KEY=sk-your-openai-key-here
#    ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here
#    STORAGE_CACHE_TYPE=redis
#    STORAGE_CACHE_HOST=localhost
#    STORAGE_CACHE_PORT=6379
#
# ============================================================================= 